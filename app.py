# Vectorise the sales response data
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import CSVLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain
from langchain_text_splitters import CharacterTextSplitter
from dotenv import load_dotenv

load_dotenv()

loader = TextLoader("the_office_data.txt")
documents = loader.load()
embeddings = OpenAIEmbeddings()
db_text = FAISS.from_documents(documents, embeddings)
print(db_text.index.ntotal)

loader2 = CSVLoader("the-office-lines.csv")
documents = loader.load()
db_script = FAISS.from_documents(documents, embeddings)
print(db_script.index.ntotal)

db_text.docstore.__dict__
db_script.docstore.__dict__

db_text.merge_from(db_script)

db_text.docstore.__dict__



# Function for similarity search
def retrieve_info(query):
    response = db_text.similarity_search(query, k=3)
    result = response[0].page_content
  #  print(result)
    return result
query = "Provide me questions from the show 'The Office' US version: References to pop culture, movies, music, etc. Parodies and homages"
similar_data = retrieve_info(query)

# Setup LLMChain and prompts
llm = ChatOpenAI(model_name="gpt-3.5-turbo")

template = """The questions should be divided in three categories: Easy, Medium and Difficult. Here is some extra info about the show that you can use to create te questions. 
{similar_data} 
This data is collected from the script of the show and some data from blog sites.
Don't make the questions read as if they were generated by AI.
IMportantly, the responses should be formatted in this way '<Question>#<Option 1>#<Option 2>#<Option 3>#<Option 4>*Answer: #<Answer>'.
Label questions by their difficulty. Indicate which is the correct answer. Do not number the questions.Provide 5 questions for each level of difficulty.
The more difficult questions may also be from facts that were released after the show in podcasts, press releases etc.""".format(similar_data = similar_data)

prompt = PromptTemplate(
    input_variables=["similar_data"],
    template = template
)

# Retrieval augmented generation

chain = prompt | llm
response = chain.invoke({query : similar_data})

# Parse question data and save to text file
with open("trivia-questions.txt", "w") as f:
    f.write(response.content)
    
#Categories of teh show used so far in retrieval:
  # quotes 
  # locations