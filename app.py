# Vectorise the sales response data
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import CSVLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain
from langchain_text_splitters import CharacterTextSplitter
from dotenv import load_dotenv

load_dotenv()

loader = TextLoader("the_office_data.txt")
documents = loader.load()
embeddings = OpenAIEmbeddings()
db_text = FAISS.from_documents(documents, embeddings)
print(db_text.index.ntotal)

loader2 = CSVLoader("the-office-lines.csv")
documents = loader.load()
db_script = FAISS.from_documents(documents, embeddings)
print(db_script.index.ntotal)

db_text.docstore.__dict__
db_script.docstore.__dict__

db_text.merge_from(db_script)

db_text.docstore.__dict__



# Function for similarity search
def retrieve_info(query):
    response = db_text.similarity_search(query, k=3)
    result = response[0].page_content
    print(result)
    return result
query = "What script data can be relevant for creating a trivia game for the Office?"
similar_data = retrieve_info(query)

# Setup LLMChain and prompts
llm = ChatOpenAI()

template = """I am creating a trivia game for 'The Office' show and would like for you to provide me with question answer pairs for my app.
The questions should be divided in three categories: Easy, Medium and Difficult. Here is some extra data that you can use to create te questions. 
{similar_data} 
This data is collected from the script of the show and some data from blog sites.

Don't make the questions read as if they were generated by AI.
Answers should be 5 comma seperated multiple choice answer options. Provide 8 questions for each level of difficulty.
The more difficult questions should be from facts that were released after the show in podcasts, press releases etc.""".format(similar_data = similar_data)

prompt = PromptTemplate(
    input_variables=["similar_data"],
    template = template
)

chain = prompt | llm
response = chain.invoke(similar_data)
print(response)

# Retrieval augmented generation